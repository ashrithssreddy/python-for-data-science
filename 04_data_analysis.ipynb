{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f60cd6",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "############################## Creating Arrays  ##############################\n",
    "np.array([1,2,3])\n",
    "np.array(range(100))\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "type(a) # numpy.ndarray\n",
    "a.dtype\n",
    "\n",
    "b = np.array([(1.5,2,3), (4,5,6)]) # , dtype = float\n",
    "type(b) # numpy.ndarray\n",
    "b.dtype # float64\n",
    "\n",
    "b2 = np.array([(1.5,2,3), (4,5,6)], dtype = float) # \n",
    "type(b2) # numpy.ndarray\n",
    "b2.dtype # float64\n",
    "\n",
    "c = np.array([[(1.5,2,3), (4,5,6)],[(3,2,1), (4,5,6)]], dtype = float)\n",
    "type(c) # numpy.ndarray\n",
    "c.dtype # float64\n",
    "\n",
    "\n",
    "np.zeros((3,4)) #Create an array of zeros\n",
    "\n",
    "np.ones((3,4)) \n",
    "np.ones((2,3,4),dtype=np.int16) #Create an array of ones\n",
    "\n",
    "np.arange(10,26,5)\n",
    "d = np.arange(10,25,5) #Create an array of evenly spaced values (step value)\n",
    "print(d)\n",
    "\n",
    "np.linspace(0,2,9) #Create an array of evenly spaced values (number of samples)\n",
    "\n",
    "np.full((2),7) # tuple for dimensions\n",
    "e = np.full((2,2),7) #Create a constant array\n",
    "print(e)\n",
    "\n",
    "f = np.eye(2) #Create a 2X2 identity matrix\n",
    "f\n",
    "\n",
    "np.random.random((2,2)) #Create an array with random values\n",
    "# np.random.random((2,2), dtype = int) # dtype not allowed?\n",
    "\n",
    "np.empty((3,2)) #Create an empty array (garbage numbers assigned)\n",
    "\n",
    "############################## I/O ##############################\n",
    "np.save('my_array' , a)\n",
    "np.savez('array.npz', a, b)\n",
    "np.load('my_array.npy')\n",
    "\n",
    "\n",
    "np.info(np.ndarray.dtype)\n",
    "\n",
    "############################## Inspecting Your Array ##############################\n",
    "a.shape #Array dimensions\n",
    "len(a) #Length of array\n",
    "b.ndim #Number of array dimensions\n",
    "b.size # 3 x 2  = 6\n",
    "e.size #Number of array elements\n",
    "b.dtype #Data type of array elements\n",
    "b.dtype.name #Name of data type\n",
    "b.astype(int) #Convert an array to a different type\n",
    "\n",
    "\n",
    "a==b\n",
    "a[1] # returns 2. type = numpy.int32 not np.ndarray\n",
    "a[a>1] # retuns array [2,3]\n",
    "\n",
    "b_temp = np.array([(1,2,3),(1,2,4) ])\n",
    "b_temp \n",
    "b_temp  == a\n",
    "a == b_temp\n",
    "np.array_equal(a,b) # False\n",
    "np.array_equal(a,a) # True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################## Aggregate functions ##############################\n",
    "a\n",
    "a.sum()\n",
    "a.max()\n",
    "\n",
    "b\n",
    "b.max(axis = 0)\n",
    "b.max(axis = 1)\n",
    "\n",
    "\n",
    "h = a.view()\n",
    "a_copy = np.copy(a)\n",
    "del(h)\n",
    "h = a.copy()\n",
    "h\n",
    "\n",
    "\n",
    "a = np.array([2,3,1])\n",
    "a.sort() # sorts in place\n",
    "\n",
    "a = np.array([2,3,1])\n",
    "sorted(a) # does not solve in place, returns a copy\n",
    "\n",
    "b_copy = np.random.random((2,3))\n",
    "b_copy \n",
    "b_copy.sort() # sorts each row left to right\n",
    "b_copy \n",
    "\n",
    "\n",
    "b_copy = np.random.random((2,3))\n",
    "b_copy \n",
    "# sorted(b_copy)\n",
    "b_copy.sort(axis=0) # sorts each row left to right\n",
    "b_copy \n",
    "\n",
    "# flatten\n",
    "np.array([[1, 2, 3], [2, 4, 5], [1, 2, 3]])\n",
    "np.array([[1, 2, 3], [2, 4, 5], [1, 2, 3]]).flatten()\n",
    "np.array([[1, 2, 3], [2, 4, 5], [1, 2, 3]]).flatten(order = \"F\")\n",
    "\n",
    "np.array([[1, 2, 3], [2, 4, 5], [1, 2, 3]]).reshape([1,9])\n",
    "np.array([[1, 2, 3], [2, 4, 5], [1, 2, 3]]).reshape((1,9))\n",
    "\n",
    "######## Slice and Dice #####\n",
    "a = np.array([1,2,3,4,5,6,7])\n",
    "a[2]\n",
    "a[a>1]\n",
    "a\n",
    "a[0:2]\n",
    "a[:4]\n",
    "a[::-1]\n",
    "a[5:0:-1]\n",
    "# a.rev\n",
    "\n",
    "b\n",
    "b[1,2]\n",
    "b[b<3]\n",
    "b[:,2] # same as b[...,2]\n",
    "\n",
    "############################## Array Manipulation ##############################\n",
    "b\n",
    "b.T\n",
    "np.transpose(b)\n",
    "\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "a\n",
    "b\n",
    "g = a-b\n",
    "\n",
    "b.ravel()\n",
    "g.reshape(3,2)\n",
    "g.reshape(3,-2)\n",
    "\n",
    "\n",
    "h = a.copy()\n",
    "# h.resize((2,6))\n",
    "h.resize((6,2))\n",
    "h\n",
    "\n",
    "h\n",
    "g\n",
    "np.append(h, g)\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "a = np.insert(a,1,5) # returns a copy, not in place\n",
    "a\n",
    "a = np.delete(a, 1)\n",
    "a\n",
    "\n",
    "\n",
    "\n",
    "############################## Concatenate ##############################\n",
    "a\n",
    "d\n",
    "np.concatenate((a,d),axis=0)\n",
    "np.concatenate((a,d),axis=1)\n",
    "\n",
    "a\n",
    "b\n",
    "np.vstack((a,b))\n",
    "\n",
    "np.vstack((a,a)) # stack them vertically, one below the other\n",
    "np.c_[a,a] # stack them as columns\n",
    "\n",
    "np.hstack((a,a)) # stack them hori, one besides the other\n",
    "np.r_[a,a] # ?\n",
    "\n",
    "\n",
    "a\n",
    "d\n",
    "np.concatenate((a,d),axis=0)\n",
    "\n",
    "a\n",
    "b\n",
    "np.vstack((a,b))\n",
    "\n",
    "e\n",
    "f\n",
    "np.r_[e,f]\n",
    "np.vstack((e,f))\n",
    "\n",
    "np.hstack((e,f))\n",
    "\n",
    "a\n",
    "d\n",
    "np.column_stack((a,d)) # same as np.c_[a,d]\n",
    "\n",
    "a\n",
    "np.hsplit(a,3)\n",
    "\n",
    "c\n",
    "np.hsplit(c,2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026abaa2",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca016476",
   "metadata": {},
   "source": [
    "############################## Create a Series/DataFrame ##############################\n",
    "import pandas as pd\n",
    "\n",
    "pd.Series([3,-5,7,4])\n",
    "pd.Series([3,-5,7,4], index = [11,12,13,14])\n",
    "s = pd.Series([3,-5,7,4], index = [\"a\",\"b\",\"c\",\"d\"])\n",
    "\n",
    "s.drop([\"a\"]) # returns a value not inplace. Inplace = F by default\n",
    "\n",
    "df = {\n",
    "      \"country\" : [\"belgium\",\"india\",\"brazil\"],\n",
    "      \"capital\" : [\"brussles\",\"delhi\",\"brasilia\"],\n",
    "      \"population\":[10,30,20]      \n",
    "      }\n",
    "df = pd.DataFrame(df)\n",
    "df\n",
    "\n",
    "df.drop(1)\n",
    "df.drop([1,2])\n",
    "\n",
    "df.drop(\"capital\", axis=1)\n",
    "df.drop([\"capital\",\"country\"], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################## Sorting ##############################\n",
    "mtcars = pd.read_csv(\"data\\\\mtcars_rownames.csv\", index_col = \"Unnamed: 0\")\n",
    "mtcars = pd.read_excel(\"data\\\\mtcars_rownames.xlsx\", index_col = \"Unnamed: 0\")\n",
    "\n",
    "df\n",
    "df.sort_values(by=\"country\")\n",
    "df.sort_values([\"country\"])\n",
    "              \n",
    "mtcars.sort_values([\"cyl\",\"vs\",\"am\",\"drat\"])\n",
    "mtcars.sort_index()\n",
    "\n",
    "mtcars = pd.read_csv(\"data\\\\mtcars_rownames.csv\", index_col = \"Unnamed: 0\").head(5)\n",
    "iris = pd.read_csv(\"data\\\\iris_rownames.csv\", index_col = \"Unnamed: 0\").head(5)\n",
    "\n",
    "############################## Selecting df - row and column position ##############################\n",
    "# give integer row positions and column positions only\n",
    "mtcars.iloc[1,1] # int\n",
    "mtcars.iloc[1,:] # series, regardless of datatypes inside the series, colon optional\n",
    "# iris.iloc[:1] # first row, not recommended due to complexity of syntax\n",
    "iris.iloc[[1],:] # DataFrame, and not a series since the inputs is list and not vector\n",
    "\n",
    "mtcars.iloc[:,1] # series, regardless of datatypes inside the series, colon mandatory\n",
    "\n",
    "mtcars.iloc[[1,2] ,[1,2]] # DataFrame\n",
    "mtcars.iloc[: ,[1,2]] # DataFrame\n",
    "\n",
    "mtcars.iat[1,1] # int, iat needs both x and y position, not recommended to use\n",
    "# mtcars.iat[1,] # do not work\n",
    "# mtcars.iat[:,1] # do not work\n",
    "# mtcars.iat[[1,2] ,[1,2]] # do not work\n",
    "# mtcars.iat[: ,[1,2]] # do not work\n",
    " \n",
    "############################## Selecting df - by row and column label ##############################\n",
    "# Input row names and column names only\n",
    "mtcars.loc[\"Datsun 710\",\"cyl\"]\n",
    "mtcars.loc[\"Datsun 710\",] # series, colon optional\n",
    "mtcars.loc[\"Datsun 710\",:] # series, colon optional\n",
    "# mtcars.loc[,\"cyl\"] # series, colon mandatory\n",
    "mtcars.loc[:,\"cyl\"] # series, colon mandatory\n",
    "# mtcars.loc[4,\"cyl\"] # failed, no rowname called 4\n",
    "# mtcars.loc[\"Datsun 710\",\"2\"] # failed, no colname called 2\n",
    "\n",
    "############################## Selecting df - by row and column label/position ##############################\n",
    "# stopped working in newer version\n",
    "\n",
    "############################## Selecting df - by boolean ##############################\n",
    "mtcars.cyl # dtype int, type series \n",
    "type(mtcars.cyl)\n",
    "(mtcars.cyl).dtypes\n",
    "\n",
    "mtcars.cyl > 4 # dtype boolean, type series\n",
    "type(mtcars.cyl > 4)\n",
    "(mtcars.cyl > 4).dtypes\n",
    "\n",
    "mtcars[mtcars.cyl > 4]\n",
    "# mtcars[some_boolean_series]\n",
    "\n",
    "s>3 #type series, dtype boolean\n",
    "s[s>3] #type series, dtype int\n",
    "s[(s>3)]\n",
    "s[~(s>3)]\n",
    "# s[!(s>3)] # does not work, negation happens using tilde ~\n",
    "s[(s>3) | (s < -3) ]\n",
    "\n",
    "\n",
    "############################## Access columns  ##############################\n",
    "mtcars.hp\n",
    "mtcars[\"hp\"]\n",
    "\n",
    "\n",
    "\n",
    "# s[\"b\"]\n",
    "# df[1]\n",
    "# mtcars[1]\n",
    "\n",
    "############################## methods/metadata and functions ##############################\n",
    "mtcars.shape\n",
    "mtcars.index # type = pandas.core.indexes.base.Index\n",
    "mtcars.columns # # type = pandas.core.indexes.base.Index\n",
    "mtcars.info()\n",
    "mtcars.dtypes # a series\n",
    "mtcars.count() # didnt understand\n",
    "\n",
    "df.sum() # sum by each colunm, a series\n",
    "mtcars.sum()\n",
    "mtcars.cumsum() # a dataframe\n",
    "mtcars.min() # a series\n",
    "mtcars.idxmin() # rowlabel corresponding to lowest value in each column\n",
    "mtcars.describe() # summary statistics\n",
    "mtcars.mean() # mean of each colunm, a series\n",
    "\n",
    "\n",
    "############################## apply functions ##############################\n",
    "f = lambda x: x + 1000\n",
    "mtcars.apply(f)\n",
    "\n",
    "f_mean = lambda x: x.mean()\n",
    "mtcars.apply(f_mean) # mean of each column\n",
    "\n",
    "f = lambda x: x + 1000\n",
    "mtcars.applymap(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################### Aggregate ###################### \n",
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\Ashrith Reddy\\My Drive\\02_learning\\python\\01_datatypes\\mtcars.csv\")\n",
    "\n",
    "# aggregate entire dataset\n",
    "f_mean = lambda x: x.mean()\n",
    "df.apply(f_mean) # mean of each column, returns a series\n",
    "\n",
    "df.groupby('am').apply(f_mean) # # mean of each column, for each group\n",
    "\n",
    "df_grouped = df.groupby('am')\n",
    "df_grouped\n",
    "type(df)\n",
    "type(df_grouped)\n",
    "df_grouped.obj # a pandas dataframe\n",
    "\n",
    "# all attributes of grouped dataframe\n",
    "df_grouped.__dict__.keys() # same as vars(df_grouped)\n",
    "\n",
    "f_sum = lambda x: x.mean()\n",
    "temp = df_grouped.apply(f_sum)\n",
    "temp # wierd behavior: aggregate the grouping column\n",
    "\n",
    "\n",
    "\n",
    "df.groupby(['vs','am']).agg(sum).reset_index()\n",
    "df.groupby(['vs','am']).agg(\"sum\").reset_index() # quotes work for built-in functions\n",
    "\n",
    "df.groupby(['vs','am']).agg(sum,max).reset_index() # fails\n",
    "df.groupby(['vs','am']).agg([\"sum\",\"max\"]).reset_index()\n",
    "\n",
    "my_sum = lambda x: x.sum()\n",
    "# df.groupby(['vs','am']).agg(\"my_sum\").reset_index() # quotes fail for UDF\n",
    "df.groupby(['vs','am']).agg(my_sum).reset_index() # no quotes preferred\n",
    "df.groupby(['vs','am']).agg(lambda x: x.sum()).reset_index()\n",
    "\n",
    "def my_sum_2(x):\n",
    "    return x.sum()\n",
    "df.groupby(['vs','am']).agg(my_sum_2).reset_index()\n",
    "\n",
    "# single groupby variable, single aggregating column\n",
    "df['disp'].groupby('vs') # wont work\n",
    "df['disp'].groupby(df.vs) # works\n",
    "df['disp'].groupby(df['vs']) # works\n",
    "df['disp'].groupby(df.vs).mean() \n",
    "\n",
    "# multiple groupby variable, single aggregating column\n",
    "df['disp'].groupby(df.vs, df.am) # fails\n",
    "df['disp'].groupby([df.vs, df.am]) # works\n",
    "df['disp'].groupby([df.vs, df.am]).mean().reset_index()\n",
    "\n",
    "# multiple groupby variable, multiple aggregating column\n",
    "df[['disp','hp']].groupby([df.vs, df.am]).mean().reset_index()\n",
    "\n",
    "# extras\n",
    "df.groupby(['vs', 'am']).size().reset_index()\n",
    "\n",
    "for group, group_data in df.groupby(['vs','am']):\n",
    "    print(\"###############\")\n",
    "    print(group)\n",
    "    print(group_data)\n",
    "\n",
    "# interchangable order of writing\n",
    "df[['disp','hp']].groupby([df.vs, df.am]).mean() # is same as \n",
    "df.groupby([df.vs, df.am])[['disp','hp']].mean() # is same as \n",
    "df.groupby([\"vs\", \"am\"])[['disp','hp']].mean() # preferred\n",
    "\n",
    "\n",
    "# multiple aggregating functions\n",
    "df.groupby([\"vs\", \"am\"])[['disp','hp']].agg(max) # max applied on disp and hp\n",
    "df.groupby([\"vs\", \"am\"])[['disp','hp']].agg([max,min]) # max applied on disp and hp, and min applied on disp and hp\n",
    "\n",
    "df.groupby([\"vs\", \"am\"])[['disp','hp']].agg({'disp':'max', 'hp':'min'}) # works\n",
    "df.groupby([\"vs\", \"am\"])[['disp','hp']].agg({'disp':max, 'hp':min}) # works\n",
    "df.groupby([\"vs\", \"am\"]).agg({'disp':max, 'hp':min}) # works\n",
    "\n",
    "# multiple aggregating functions - different functions for each aggregating column\n",
    "df.groupby([\"vs\", \"am\"]).agg({\n",
    "    'disp':max, \n",
    "    'hp':min,\n",
    "    'gear':lambda x: x.max() - x.min()\n",
    "    })\n",
    "\n",
    "df.groupby([\"vs\", \"am\"]).agg({\n",
    "    'disp':[max, min, lambda x: x.max() - x.min()], \n",
    "    'hp':min,    \n",
    "    })\n",
    "\n",
    "df.groupby([\"vs\", \"am\"]).agg({\n",
    "    'disp':lambda x: x.max() - x.min(), \n",
    "    'hp':lambda x: x.min() - x.max(),    \n",
    "    })\n",
    "\n",
    "\n",
    "# rename columns after aggregating\n",
    "temp = df.groupby([\"vs\", \"am\"]).agg({\n",
    "    'disp':[max, min, lambda x: x.max() - x.min()], \n",
    "    'hp':min,    \n",
    "    })\n",
    "print(temp)\n",
    "temp.columns = ['_'.join(x) for x in temp.columns]\n",
    "print(temp.reset_index())\n",
    "\n",
    "\n",
    "# name columns while aggregating :)\n",
    "df.groupby([\"vs\", \"am\"]).agg(\n",
    "    min_disp=('disp','min'),\n",
    "    max_disp=('disp','max'),\n",
    "    max_hp=('hp','max'),\n",
    "    min_hp=('hp',min),\n",
    "    range_hp=('hp',lambda x: x.max()-x.min()),  # interestingly, a comma is allowed after last aggegation\n",
    "    )\n",
    "\n",
    "# additional features\n",
    "df.groupby([\"vs\", \"am\"], as_index = False).agg(\n",
    "    min_disp=('disp','min'),\n",
    "    )# avoid having to reset_index()\n",
    "\n",
    "df.groupby([\"vs\", \"am\"]).agg(\n",
    "    min_disp=('disp','min'),\n",
    "    )# avoid having to reset_index()\n",
    "\n",
    "\n",
    "############################## grouped-mutate ##############################\n",
    "# import numpy as np\n",
    "# df.groupby(\"cyl\").apply(max(hp))\n",
    "df.groupby(\"cyl\")[\"hp\"].transform(\"sum\") \n",
    "df.groupby(\"cyl\")[\"hp\"].transform(sum)\n",
    "df.groupby(\"cyl\")[\"hp\"].transform(lambda x: sum(x)/(1000 + 10))\n",
    "df.groupby(\"cyl\")[[\"hp\",\"mpg\"]].transform(lambda x: sum(x))\n",
    "\n",
    "def temp_fun(x):\n",
    "    # print(\"###########################\")\n",
    "    # print(x)\n",
    "    answer = sum(x.vs) - sum(x.am)\n",
    "    return answer\n",
    "\n",
    "# df.groupby(\"cyl\").transform(temp_fun)\n",
    "\n",
    "temp = df.groupby(\"cyl\").\\\n",
    "    apply(temp_fun).\\\n",
    "    to_frame().\\\n",
    "    rename(columns={0:\"vs_as\"}).\\\n",
    "    reset_index()\n",
    "df.merge(temp)\n",
    "\n",
    "\n",
    "# lambda x: \n",
    "# sum(x)\n",
    "    # sum(x[0]-x[1])\n",
    "    # print(\"\")\n",
    "\n",
    "# [[\"hp\",\"mpg\"]]\n",
    "# .groupby(\"cyl\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################## advanced functions ##############################\n",
    "# first value, count, \n",
    "df.groupby('cyl').agg(first_disp=('disp',nth(0)))\n",
    "df.groupby('cyl')[\"disp\",\"hp\"].nth(0)\n",
    "df.groupby('cyl')[\"disp\",\"hp\"].nth(1)\n",
    "agg(first_disp=('disp',))\n",
    "\n",
    "nth(0)\n",
    "df.nth(1)\n",
    "\n",
    "\n",
    "############################## Others ##############################\n",
    "df[\"new\"] = 999\n",
    "df\n",
    "df[\"new\"] = None\n",
    "\n",
    "df.head(3)\n",
    "df.tail(3)\n",
    "\n",
    "df.shape\n",
    "\n",
    "############################## spread and gather/pivot ##############################\n",
    "\n",
    "\n",
    "############################## data alignment ##############################\n",
    "s\n",
    "s3 = pd.Series([100,100,100], index = [\"a\",\"c\",\"d\"])\n",
    "s3 \n",
    "\n",
    "s + s3\n",
    "\n",
    "\n",
    "# replace a value in DF\n",
    "mtcars = pd.read_csv(r\"C:/Users/Ashrith Reddy/My Drive/02_learning/python/02_data_analysis/mtcars.csv\")\n",
    "mtcars.iloc[0,0] = 999\n",
    "mtcars.loc[:,\"newcol2\"] = 999 \n",
    "mtcars.loc[:,\"newcol2\"] = [999, 1000] # Does not recycle\n",
    "\n",
    "\n",
    "mtcars.columns\n",
    "mtcars.describe()\n",
    "type(mtcars) == pandas.core.frame.DataFrame # Fails\n",
    "isinstance(mtcars, pd.DataFrame)\n",
    "\n",
    "mtcars_1 = mtcars[mtcars.cyl==4]\n",
    "mtcars_2 = mtcars[mtcars.cyl==6]\n",
    "# bind with mismatching column/row count?\n",
    "pd.concat(mtcars_1, mtcars_2) # fails\n",
    "pd.concat([mtcars_1, mtcars_2]) \n",
    "[mtcars_1, mtcars_2] # list of dataframes\n",
    "# OR \n",
    "mtcars_1.append(mtcars_2)\n",
    "\n",
    "\n",
    "mtcars_1 = mtcars.iloc[:,0:5]\n",
    "mtcars_2 = mtcars.iloc[:,5:12]\n",
    "mtcars_1_2 = pd.concat([mtcars_1, mtcars_2], axis = 1) # correct way\n",
    "mtcars_1_2_bad = pd.concat([mtcars_1, mtcars_2], axis = 1, ignore_index=True) # screws up the column names\n",
    "\n",
    "############################ Pending ############################ \n",
    "# apply a function to every element of data.frame\n",
    "# like apply(X= mat,MARGIN=c(1,2),FUN=sqrt) # Instructs to apply sum on mat, row-wise and col-wise. i.e. on each element of matrix\n",
    "\n",
    "# Question: Get the number of missing values in each column of credit dataset\n",
    "# mat <- matrix(runif(24,-10,10),6,4) # runif generates 24 random numbers between -10 and 10\n",
    "# Question: Find number of negative entries in each row of matrix\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
